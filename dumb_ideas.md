## Collection of random, probably stupid ideas

How can we bring dead neurons back to life: Can we randomly initialize them during training? Can we feed them rediculous data to wake them up?  Look at [synaptic stripping](https://arxiv.org/pdf/2302.05818.pdf)

Could we lie about gradients? Rather than using the real gradients to update weights, are there use cases where altering the gradient (like with relus) could help avoid 

Should we use our loss function to punish weights by zero the same way we do with weight decay